{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f105fbed-3cf1-42fb-aa2c-bf1dfaee6f5a",
   "metadata": {},
   "source": [
    "<b><font color=\"SteelBlue\" size=\"+3\">Classifiez automatiquement des biens de consommation</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ecccb-d303-4f80-83fe-4dacb82dc07b",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3d070-048b-4807-8977-30dbe4e240c7",
   "metadata": {},
   "source": [
    "Ce notebook est la suite de celui sur le traitement des descriptions. On récupère les données nettoyées pour les catégories des produits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921c1bd-b2f0-4f93-aeee-0715f899f711",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4f0271-1e10-4c6f-9551-57ea20d9c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies\n",
    "# Standard\n",
    "import os\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image Processing\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Deep Learning - TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.applications import InceptionResNetV2, DenseNet201\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg16\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_inceptionresnetv2\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_densenet201\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Custom Modules\n",
    "from Deveau_Estelle_4_IMG_func_042024 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f1bb6-53d0-4efc-82c1-b035269391ef",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86df606e-6b8a-47f3-bbe7-f34d5f0a5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data',\n",
       " 'Deveau_Estelle_1_notebook_txt_faisabilite_042024.ipynb',\n",
       " 'Deveau_Estelle_2_NLP_func_042024.py',\n",
       " 'Deveau_Estelle_3_notebook_img_042024.ipynb',\n",
       " 'Deveau_Estelle_3_notebook_img_classification_042024-Copy1.ipynb',\n",
       " 'Deveau_Estelle_4_IMG_func_042024.py',\n",
       " 'Deveau_Estelle_5_notebook_img_042024.ipynb',\n",
       " 'model_densenet201_best.weights.h5',\n",
       " 'model_inceptionresnetv2_best.weights.h5',\n",
       " 'model_vgg16_best.weights.h5',\n",
       " 'OC_projet6.pptx',\n",
       " 'pythonProject',\n",
       " 'svg',\n",
       " 'Weather_Images_CNN_Transfer_Learning_Stage_1_feasibility_V1.0.ipynb',\n",
       " 'Weather_Images_CNN_Transfer_Learning_Stage_2_supervised_classification_V1.0.ipynb',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3db40d-660c-49fe-a8b5-58307c30d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"data/Cleaned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbe1e8a-1f51-4a87-99ee-2c712fe1fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path     = \"./data/Cleaned/\"\n",
    "filename = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c1a96b-b4ea-48a3-b878-c5482f7c690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d37600a-66aa-4b58-98c0-17ba57ad2c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n"
     ]
    }
   ],
   "source": [
    "path     = \"./data/Sources/Images/\"\n",
    "list_photos = [file for file in os.listdir(path)]\n",
    "print(len(list_photos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea98bc1-c7cf-4f3d-bce2-c7b35748888c",
   "metadata": {},
   "source": [
    "# Classification supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c595dd67-13b7-4e77-bc48-f69daced73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [f\"{path}{uid}.jpg\" for uid in df['uniq_id']]\n",
    "\n",
    "# Encodage des catégories\n",
    "label_encoder = LabelEncoder()\n",
    "categories_encoded = label_encoder.fit_transform(df['product_category'])\n",
    "category_names = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62125576-6a38-439c-a7fe-4e8c86989d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fct(base_model_name='VGG16'):\n",
    "    \"\"\"\n",
    "    Crée et compile un modèle de classification d'images basé sur un modèle CNN pré-entraîné.\n",
    "    \n",
    "    Args:\n",
    "    - base_model_name (str): Nom du modèle CNN pré-entraîné à utiliser.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Le modèle Keras compilé.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sélection du modèle de base en fonction du nom fourni\n",
    "    if base_model_name == 'InceptionResNetV2':\n",
    "        base_model = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=(299, 299, 3))\n",
    "    elif base_model_name == 'DenseNet201':\n",
    "        base_model = DenseNet201(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "    elif base_model_name == 'EfficientNetB7':\n",
    "        base_model = EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=(600, 600, 3))\n",
    "    else:  # Le modèle par défaut est VGG16 si aucun nom valide n'est fourni\n",
    "        base_model = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "    # extraction des features\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Construction du modèle\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "    # Définition du nouveau modèle\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compilation du modèle\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Affichage du résumé du modèle\n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d77d8-9f25-49c3-b688-144744f95450",
   "metadata": {},
   "source": [
    "## Séparation des jeux de données (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb6d996a-e292-4443-9330-b8a3cedf2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(categories_encoded, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b38d11a-2658-4c6e-8f77-42e5c0168c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d124dd0d-078e-4f1f-ad40-ae4f190af400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les chemins d'image et les étiquettes\n",
    "paths_train, paths_test, y_train, y_test = train_test_split(image_paths, y, test_size=0.2, random_state=42)\n",
    "paths_train, paths_val, y_train, y_val = train_test_split(paths_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561563c0-7d61-4b13-9a59-dadac0839736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a0379ad-a27f-4d55-b7b4-022784eddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les résultats\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78657f7c-c53a-4d6d-9343-163da34a541b",
   "metadata": {},
   "source": [
    "## Evaluation des modèles sélectionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e07845a3-b35d-4ca0-87e6-7b69a10e1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le seuil à un niveau supérieur spécifique\n",
    "PilImage.MAX_IMAGE_PIXELS = 100000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be926cf2-7849-4691-9a8e-e34a1370db16",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "024d4f2a-cbb8-4fcb-bec4-cb89810a3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données\n",
    "X_train_vgg16, X_val_vgg16, X_test_vgg16 = prepare_data(paths_train, paths_val, paths_test, preprocess_vgg16,\n",
    "                                                        target_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9f37f9-21bb-41a2-ab4e-b6224ef61387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "model_vgg16 = create_model_fct(base_model_name='VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3981c122-d4a3-4067-b3cb-326d0ca3d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2991 - loss: 9.0048\n",
      "Epoch 1: val_loss improved from inf to 1.42300, saving model to ./model_vgg16_best.weights.h5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.3095 - loss: 8.7589 - val_accuracy: 0.7286 - val_loss: 1.4230\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6397 - loss: 2.2318\n",
      "Epoch 2: val_loss improved from 1.42300 to 1.31556, saving model to ./model_vgg16_best.weights.h5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.6402 - loss: 2.2286 - val_accuracy: 0.7238 - val_loss: 1.3156\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7469 - loss: 1.4657\n",
      "Epoch 3: val_loss improved from 1.31556 to 1.09488, saving model to ./model_vgg16_best.weights.h5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.7451 - loss: 1.4647 - val_accuracy: 0.7571 - val_loss: 1.0949\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7966 - loss: 0.8769\n",
      "Epoch 4: val_loss improved from 1.09488 to 1.09044, saving model to ./model_vgg16_best.weights.h5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.7952 - loss: 0.8821 - val_accuracy: 0.7905 - val_loss: 1.0904\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8388 - loss: 0.4958\n",
      "Epoch 5: val_loss improved from 1.09044 to 1.05707, saving model to ./model_vgg16_best.weights.h5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.8383 - loss: 0.5021 - val_accuracy: 0.7714 - val_loss: 1.0571\n",
      "Epoch 6/50\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.8585 - loss: 0.4985"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_vgg16, history_vgg16, duration_vgg16 \u001b[38;5;241m=\u001b[39m train_model(model_vgg16, X_train_vgg16, y_train, X_val_vgg16, y_val,\n\u001b[0;32m      3\u001b[0m                                                          model_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model_vgg16_best.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OpenClassrooms\\Projets\\Projet 6\\Deveau_Estelle_4_IMG_func_042024.py:224\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, X_val, y_val, model_save_path)\u001b[0m\n\u001b[0;32m    222\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint, es]\n\u001b[0;32m    223\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mRMSprop(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 224\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39mcallbacks_list, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# Fin du chronométrage\u001b[39;00m\n\u001b[0;32m    227\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model_vgg16, history_vgg16, duration_vgg16 = train_model(model_vgg16, X_train_vgg16, y_train, X_val_vgg16, y_val,\n",
    "                                                         model_save_path=\"./model_vgg16_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d62e5-dd68-44a0-b5d1-dc0bd612dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "loss_vgg16, accuracy_vgg16, ari_score_vgg16 = evaluate_model(model_vgg16, X_train_vgg16, y_train, X_val_vgg16,\n",
    "                                                             y_val, X_test_vgg16, y_test, best_weights_path=\"./model_vgg16_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51705f37-d878-45ec-ba4d-65813c87927b",
   "metadata": {},
   "source": [
    "### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74779ef2-ba20-4899-a4d8-cf893153a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données\n",
    "X_train_inceptionresnetv2, X_val_inceptionresnetv2, X_test_inceptionresnetv2 = prepare_data(paths_train, paths_val,\n",
    "                                                                                            paths_test, preprocess_inceptionresnetv2,\n",
    "                                                                                            target_size=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834c6c6-76d9-4f8a-b7a2-1eeb9e7149a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "model_inceptionresnetv2 = create_model_fct(base_model_name='InceptionResNetV2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f0a2f-5529-4029-b6f5-a99e0260f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "model_iresnetv2, history_iressnetv2, duration_iresnetv2 = train_model(model_inceptionresnetv2, X_train_inceptionresnetv2,\n",
    "                                                                      y_train, X_val_inceptionresnetv2, y_val,\n",
    "                                                                      model_save_path=\"./model_inceptionresnetv2_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c57b95-2844-40bd-89b6-5b4fb91c796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "loss_inceptionresnetv2, accuracy_inceptionresnetv2, ari_score_inceptionresnetv2 = evaluate_model(model_inceptionresnetv2,\n",
    "                                                                                                 X_train_inceptionresnetv2,\n",
    "                                                                                                 y_train, X_val_inceptionresnetv2,\n",
    "                                                                                                 y_val, X_test_inceptionresnetv2,\n",
    "                                                                                                 y_test,\n",
    "                                                                                                 best_weights_path=\"./model_inceptionresnetv2_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de738ea6-874e-439e-bf2e-74ed405ba278",
   "metadata": {},
   "source": [
    "### DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0ecdc-e29a-4c04-905f-82319f9c3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données\n",
    "X_train_densenet201, X_val_densenet201, X_test_densenet201 = prepare_data(paths_train, paths_val, paths_test,\n",
    "                                                                          preprocess_densenet201, target_size=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a913f-66ac-4adc-8757-f60368ec2e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "model_densenet201 = create_model_fct(base_model_name='DenseNet201')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d2a50-eb0c-4c12-8b9f-d5fb1d81fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "model_densenet201, history_densenet201, duration_densenet201 = train_model(model_densenet201, X_train_densenet201, y_train,\n",
    "                                                                           X_val_densenet201, y_val,\n",
    "                                                                           model_save_path=\"./model_densenet201_best.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f25fb0-8191-474b-88a5-2ad4bf309a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "loss_densenet201, accuracy_densenet201, ari_score_densenet201 = evaluate_model(model_densenet201, X_train_densenet201,\n",
    "                                                                               y_train, X_val_densenet201,\n",
    "                                                                                y_val, X_test_densenet201, y_test,\n",
    "                                                                               best_weights_path=\"./model_densenet201_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e99361-c715-4afa-853e-222ed27935b2",
   "metadata": {},
   "source": [
    "### Comparaison des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882c8c9-2fcf-4a83-be74-0a6012d0d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la liste pour stocker les résultats\n",
    "data_results = []\n",
    "\n",
    "# Fonction pour ajouter les résultats d'un modèle au DataFrame\n",
    "def add_results(model_name, loss, accuracy, ari_score, duration):\n",
    "    metrics = ['Loss', 'Accuracy', 'Adjusted Rand Score', 'Duration (en heures)']\n",
    "    scores = [loss, accuracy, ari_score, (duration/3600)]\n",
    "    for metric, score in zip(metrics, scores):\n",
    "        data_results.append({\n",
    "            'Model': model_name,\n",
    "            'Metric': metric,\n",
    "            'Score': score\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec292a92-295a-4ff5-b03b-b2d3af07a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_results('VGG16', loss_vgg16, accuracy_vgg16, ari_score_vgg16, duration_vgg16)\n",
    "add_results('InceptionResNetV2', loss_inceptionresnetv2, accuracy_inceptionresnetv2, ari_score_inceptionresnetv2, duration_iresnetv2)\n",
    "add_results('DenseNet201', loss_densenet201, accuracy_densenet201, ari_score_densenet201, duration_densenet201)\n",
    "\n",
    "data_metrics = pd.DataFrame(data_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9737b-c941-44b3-b556-fc5fb1a33503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(data_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb95ce-bd7a-47f6-8b03-99be68d198cc",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccf6d0-9182-49b2-992c-7bc576e52011",
   "metadata": {},
   "source": [
    "## Hyper paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4a482-d159-4fc0-81ae-26fe35326e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "bestmodel, duration_best = train_model_with_search(model_inceptionresnetv2, X_train_inceptionresnetv2, y_train, X_val_inceptionresnetv2, y_val,\n",
    "                                                   model_save_path=\"./model_best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10ade4-380a-423e-b2e7-1e60293c9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "loss_best, accuracy_best, ari_score_best = evaluate_model(bestmodel,\n",
    "                                                          X_train_inceptionresnetv2,\n",
    "                                                          y_train, X_val_inceptionresnetv2,\n",
    "                                                          y_val, X_test_inceptionresnetv2,\n",
    "                                                          y_test, best_weights_path=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c686df-c302-49fc-8f0b-e5607faffefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_results('InceptionResNetV2 (HP)', loss_best, accuracy_best, ari_score_best, duration_best)\n",
    "\n",
    "data_metrics = pd.DataFrame(data_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de19df-9f69-4a78-937d-6b49ecc2067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(data_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315c260-a1ae-4a45-9a18-d32dde463c6b",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0fc41-bcf5-48a6-ba9a-3342ef6c4331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868338c9-ed13-4f80-b30c-3d1976ea4cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94baec4a-cd19-4525-b90d-093cdd96420c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fdb6e-fb5b-44a8-9fff-d225a153a1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f40f7-a6a4-4c75-b00b-d7ba914854a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4f4a0-a86d-4996-97f2-d7fe420e7263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7de8ef-dd9d-4ae9-a8dd-ab86621421c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
